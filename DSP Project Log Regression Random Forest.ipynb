{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, r2_score, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X = pd.read_csv(r'C:\\Users\\Krish\\Desktop\\OneDrive - The University of Texas at Austin\\UT Austin\\Data Science Programming\\Project\\input.csv')\n",
    "y = pd.read_csv(r'C:\\Users\\Krish\\Desktop\\OneDrive - The University of Texas at Austin\\UT Austin\\Data Science Programming\\Project\\output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Regression functions\n",
    "\n",
    "def run_LogisticReg(train_X, test_X, train_y, test_y, plot_graph, classification_thres, print_report ):\n",
    "    \n",
    "    model = LogisticRegression(class_weight='balanced',max_iter=5000, solver='lbfgs')\n",
    "    model.fit(train_X, train_y)\n",
    "\n",
    "    yhat = model.predict_proba(test_X)\n",
    "    yhat_positive = yhat[:, 1]\n",
    "\n",
    "    y_pred = (model.predict_proba(test_X)[:,1]>classification_thres).astype(bool)\n",
    "\n",
    "    if print_report =='Yes':\n",
    "        print(classification_report(test_y, y_pred))\n",
    "\n",
    "    feature_importance = pd.DataFrame(train_X.columns, columns = [\"feature\"])\n",
    "    feature_importance[\"importance\"] = model.coef_[0]\n",
    "    feature_importance = feature_importance.sort_values(by = [\"importance\"], ascending=True)\n",
    "\n",
    "    if plot_graph == 'Yes':\n",
    "        ax = feature_importance.plot.barh(x='feature', y='importance')\n",
    "        plt.rcParams[\"figure.figsize\"]=(10,10)\n",
    "        plt.show()\n",
    "\n",
    "    return yhat, yhat_positive, y_pred, feature_importance\n",
    "\n",
    "\n",
    "def perform_cross_validation(X, y, n_splits1):\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits1,shuffle=True,random_state=42)\n",
    "    pred_test_full =0\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    accuracy_list = []\n",
    "    roc_auc_list = []\n",
    "    i=1\n",
    "\n",
    "    for train_index,test_index in kf.split(X,y):\n",
    "        \n",
    "        print('{} of KFold {}'.format(i,kf.n_splits))\n",
    "        xtr,xvl = X.loc[train_index],X.loc[test_index]\n",
    "        ytr,yvl = y.loc[train_index],y.loc[test_index]\n",
    "        \n",
    "        yhat, yhat_positive, y_pred, feature_importance = run_LogisticReg(train_X=xtr, test_X=xvl, train_y=ytr, test_y=yvl, plot_graph='No',classification_thres=0.45, print_report='Yes' )\n",
    "        \n",
    "        precision = precision_score(y_pred=y_pred, y_true=yvl)\n",
    "        recall = recall_score(y_pred=y_pred, y_true=yvl)\n",
    "        accuracy = accuracy_score(y_pred=y_pred, y_true=yvl)\n",
    "        roc_score = roc_auc_score(yvl, yhat_positive)\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        accuracy_list.append(accuracy)\n",
    "        roc_auc_list.append(roc_score)\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(yvl,  yhat_positive)\n",
    "        length = len(thresholds)\n",
    "\n",
    "        plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "        plt.plot(fpr, tpr, label='Logistic')\n",
    "        idx_list  =np.linspace(0,length, num=20).astype(int)\n",
    "\n",
    "        for ix in idx_list:\n",
    "            try:\n",
    "                plt.scatter(fpr[ix], tpr[ix], marker='o', color='red', label=thresholds[ix])\n",
    "                plt.text(fpr[ix], tpr[ix], str(round(thresholds[ix],2)))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "#         #Calculate accuracy, precision_score, recall_score, specificity, confusion matrix and classification report\n",
    "#         ps = precision_score(test_y, y_pred)\n",
    "#         print('Precision Score =',ps)\n",
    "#         rs = recall_score(test_y, y_pred)\n",
    "#         print('Recall Score =',rs)\n",
    "#         tn, fp, fn, tp = confusion_matrix(test_y, y_pred).ravel()\n",
    "#         specificity = tn / (tn+fp)\n",
    "#         print('Specificity =',specificity)\n",
    "#         cm = confusion_matrix(test_y, y_pred)\n",
    "#         print(cm)\n",
    "#         print(classification_report(test_y, y_pred))\n",
    "\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    return precision_list, recall_list, accuracy_list, roc_auc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running logistic regression considering all the features with l2 regularization\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train_scaled = np.array(y_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "y_test_scaled = np.array(y_test)\n",
    "\n",
    "yhat, yhat_positive, y_pred, feature_importance = run_LogisticReg(X_train, X_test, y_train, y_test, plot_graph='No',classification_thres=0.45, print_report='Yes' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "precision_list1, recall_list1, accuracy_list1, roc_auc_list1 = perform_cross_validation(X,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RandomForest(X_train, X_test, Y_train, Y_test, classification_thres ):\n",
    "    \n",
    "    #Random Forest model\n",
    "    rf = RandomForestClassifier(n_estimators= 19, max_depth= 12, class_weight='balanced')\n",
    "    rf.fit(X_train, Y_train)\n",
    "    yhat = rf.predict_proba(X_test)\n",
    "    yhat_positive = yhat[:, 1]\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    y_pred = (rf.predict_proba(X_test)[:,1]>0.45).astype(bool)\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    \n",
    "    # calculate inputs for the roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, yhat_positive)\n",
    "\n",
    "    #Calculate ROC Score\n",
    "    roc_score = roc_auc_score(Y_test, yhat_positive)\n",
    "    print(\"ROC_AUC: \"+ str(roc_score))\n",
    "    print('\\n')\n",
    "    \n",
    "    return yhat, yhat_positive, y_pred\n",
    "\n",
    "#Cross Validation function\n",
    "\n",
    "def perform_cross_validation(X, y, n_splits1):\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits1,shuffle=True,random_state=42)\n",
    "    pred_test_full =0\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    accuracy_list = []\n",
    "    roc_auc_list = []\n",
    "    i=1\n",
    "\n",
    "    for train_index,test_index in kf.split(X,y):\n",
    "        \n",
    "        print('{} of KFold {}'.format(i,kf.n_splits))\n",
    "        xtr,xvl = X.loc[train_index],X.loc[test_index]\n",
    "        ytr,yvl = y.loc[train_index],y.loc[test_index]\n",
    "        \n",
    "        yhat, yhat_positive, y_pred = run_RandomForest(X_train=xtr, Y_train=ytr, X_test=xvl, Y_test=yvl, classification_thres=0.45)\n",
    "        \n",
    "        precision = precision_score(y_pred=y_pred, y_true=yvl)\n",
    "        recall = recall_score(y_pred=y_pred, y_true=yvl)\n",
    "        accuracy = accuracy_score(y_pred=y_pred, y_true=yvl)\n",
    "        roc_score = roc_auc_score(yvl, yhat_positive)\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        accuracy_list.append(accuracy)\n",
    "        roc_auc_list.append(roc_score)\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(yvl,  yhat_positive)\n",
    "        length = len(thresholds)\n",
    "\n",
    "        plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "        plt.plot(fpr, tpr, label='Logistic')\n",
    "        idx_list  =np.linspace(0,length, num=20).astype(int)\n",
    "\n",
    "        for ix in idx_list:\n",
    "            try:\n",
    "                plt.scatter(fpr[ix], tpr[ix], marker='o', color='red', label=thresholds[ix])\n",
    "                plt.text(fpr[ix], tpr[ix], str(round(thresholds[ix],2)))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    return precision_list, recall_list, accuracy_list, roc_auc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into Training and Testing data sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.20, train_size = 0.80, random_state= 42)\n",
    "\n",
    "#Calling the Random Forest Function\n",
    "yhat, yhat_positive, y_pred = run_RandomForest(X_train, X_test, Y_train, Y_test,classification_thres=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find the optimal tree depth\n",
    "df = pd.DataFrame(columns=['Ival','Rs'])\n",
    "\n",
    "for i in range(1,50):\n",
    "    rf = RandomForestClassifier(n_estimators= 10, max_depth= i, class_weight='balanced')\n",
    "    rf.fit(X_train, Y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    rs = recall_score(Y_test, y_pred)\n",
    "    df=df.append({'Ival':i,'Rs':rs},ignore_index=True)\n",
    "print(df)\n",
    "df.plot.line(x='Ival',y='Rs',style='.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find the optimal number of estimators\n",
    "df = pd.DataFrame(columns=['n_estimators','Rs'])\n",
    "\n",
    "for j in range(1,100):\n",
    "    rf = RandomForestClassifier(n_estimators= j, max_depth= 12, class_weight='balanced')\n",
    "    rf.fit(X_train, Y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    rs = recall_score(Y_test, y_pred)\n",
    "    df=df.append({'n_estimators':j,'Rs':rs},ignore_index=True)\n",
    "print(df)\n",
    "df.plot.line(x='n_estimators',y='Rs',style='.-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
